{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment _TextAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDLT45gA22H2iAVgdEV3TH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shi-star/Text_Sentiment_Analysis_movie_review/blob/main/Sentiment__TextAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOea5NxEPRMJ",
        "outputId": "ce0246a9-3e62-43e7-ce2c-231e58a5c59a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jtf8NYHQHpg"
      },
      "source": [
        "path = '/content/drive/MyDrive/archive.zip'"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YstrDZ8XXdfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e797a3bb-9c1e-40cd-e3a0-2e70120abdb5"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rehIxEzCtosg"
      },
      "source": [
        "1. We have imported NLTK (Natural Language ToolKit), for stopping, stemming, lemmatization\n",
        "2. nltk.download('punkt') # default download,It is downloaded default as available in the package\n",
        "3. nltk.download('stopwords') # downloading the stopwords to be used in the stopping process\n",
        "4. nltk.download('wordnet') # downloading wordnet(is like imagenet for text) text data for stemming and lemmatization purpose\n",
        "5. from nltk.corpus import stopwords # imports the stopwords we can use\n",
        "6. from nltk.stem.wordnet import WordNetLemmatizer # Lemmatizer \n",
        "7. import re # Regular Expression, RegEx\n",
        "8. from sklearn.feature_extraction.text import TfidfVectorizer (to calculate TF, IDF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeS1KHPlXXtx"
      },
      "source": [
        "txt = pd.read_csv(path, nrows = 1000)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEpP0gpsuZla"
      },
      "source": [
        "Although the data has 25000 rows, but it didn't run well so I took only 1000 rows of the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "K_RxAbGGXcKL",
        "outputId": "646d14fc-7898-4702-d4e0-28372acec3e9"
      },
      "source": [
        "txt.head()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Positive</td>\n",
              "      <td>With all this stuff going down at the moment w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Positive</td>\n",
              "      <td>'The Classic War of the Worlds' by Timothy Hin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Negative</td>\n",
              "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Negative</td>\n",
              "      <td>It must be assumed that those who praised this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                             review\n",
              "0  Positive  With all this stuff going down at the moment w...\n",
              "1  Positive  'The Classic War of the Worlds' by Timothy Hin...\n",
              "2  Negative  The film starts with a manager (Nicholas Bell)...\n",
              "3  Negative  It must be assumed that those who praised this...\n",
              "4  Positive  Superbly trashy and wondrously unpretentious 8..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E49uC0Wwuk07"
      },
      "source": [
        "Glimpse of the Data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXSD4a6XXhIE"
      },
      "source": [
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Oj9ZVr6unrc"
      },
      "source": [
        "Forgot to import :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9UhSzzMZFYQ",
        "outputId": "e648c8c7-226b-4146-9b85-05552c58fb81"
      },
      "source": [
        "txt.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2oHW_G3usi5"
      },
      "source": [
        "We have 1000 rows and 2 columns, one is target column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXT6OIZwZK7y",
        "outputId": "32d6ad31-9a55-4b7d-acd6-20adfad448ad"
      },
      "source": [
        "txt['sentiment'].value_counts()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Negative    518\n",
              "Positive    482\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW9C0eKuu03_"
      },
      "source": [
        "We can see we have balanced data . almost an equal number of both the sentiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP6lE3o9ZRC2"
      },
      "source": [
        "dict1 = {'Positive':1, 'Negative':0}"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOVyETa5u9lF"
      },
      "source": [
        "So let's change them into numerical so that it will be easy to process further "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhyp8C7QZulg"
      },
      "source": [
        "txt['sentiment'] = txt['sentiment'].map(dict1)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxwr9bu3Z1e_",
        "outputId": "96a235be-e488-4103-d68d-4f023eb54287"
      },
      "source": [
        "txt['sentiment'].value_counts()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    518\n",
              "1    482\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "PsubGY7n4LoH",
        "outputId": "7c430fda-5059-4f6d-926e-b79a34fa57f9"
      },
      "source": [
        "txt['review'][1]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"'The Classic War of the Worlds' by Timothy Hines is a very entertaining film that obviously goes to great effort and lengths to faithfully recreate H. G. Wells' classic book. Mr. Hines succeeds in doing so. I, and those who watched his film with me, appreciated the fact that it was not the standard, predictable Hollywood fare that comes out every year, e.g. the Spielberg version with Tom Cruise that had only the slightest resemblance to the book. Obviously, everyone looks for different things in a movie. Those who envision themselves as amateur 'critics' look only to criticize everything they can. Others rate a movie on more important bases,like being entertained, which is why most people never agree with the 'critics'. We enjoyed the effort Mr. Hines put into being faithful to H.G. Wells' classic novel, and we found it to be very entertaining. This made it easy to overlook what the 'critics' perceive to be its shortcomings.'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41hEaKdVvGYD"
      },
      "source": [
        "We can see second row of the data, and we can see each row has a lot of text in it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zELIkfV0IX4"
      },
      "source": [
        "#**1.Creating Columns for TF-IDF table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTONcdnc0gCw"
      },
      "source": [
        "text = ''\n",
        "\n",
        "for i in txt['review']:\n",
        "  text += re.sub('[^a-z ]', '', i.strip().lower())+' '\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJpWN2-EvNYx"
      },
      "source": [
        "Here we have taken each row and then applied the regex function on each row to remove all the character except (a-z and a space)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCfIVsP9vzRA"
      },
      "source": [
        "# **Tokenisation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u6O_Omw0gH7",
        "outputId": "c353466a-a6c5-4e89-ea90-480bb099de45"
      },
      "source": [
        "nltk.word_tokenize(text)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['with',\n",
              " 'all',\n",
              " 'this',\n",
              " 'stuff',\n",
              " 'going',\n",
              " 'down',\n",
              " 'at',\n",
              " 'the',\n",
              " 'moment',\n",
              " 'with',\n",
              " 'mj',\n",
              " 'ive',\n",
              " 'started',\n",
              " 'listening',\n",
              " 'to',\n",
              " 'his',\n",
              " 'music',\n",
              " 'watching',\n",
              " 'the',\n",
              " 'odd',\n",
              " 'documentary',\n",
              " 'here',\n",
              " 'and',\n",
              " 'there',\n",
              " 'watched',\n",
              " 'the',\n",
              " 'wiz',\n",
              " 'and',\n",
              " 'watched',\n",
              " 'moonwalker',\n",
              " 'again',\n",
              " 'maybe',\n",
              " 'i',\n",
              " 'just',\n",
              " 'want',\n",
              " 'to',\n",
              " 'get',\n",
              " 'a',\n",
              " 'certain',\n",
              " 'insight',\n",
              " 'into',\n",
              " 'this',\n",
              " 'guy',\n",
              " 'who',\n",
              " 'i',\n",
              " 'thought',\n",
              " 'was',\n",
              " 'really',\n",
              " 'cool',\n",
              " 'in',\n",
              " 'the',\n",
              " 'eighties',\n",
              " 'just',\n",
              " 'to',\n",
              " 'maybe',\n",
              " 'make',\n",
              " 'up',\n",
              " 'my',\n",
              " 'mind',\n",
              " 'whether',\n",
              " 'he',\n",
              " 'is',\n",
              " 'guilty',\n",
              " 'or',\n",
              " 'innocent',\n",
              " 'moonwalker',\n",
              " 'is',\n",
              " 'part',\n",
              " 'biography',\n",
              " 'part',\n",
              " 'feature',\n",
              " 'film',\n",
              " 'which',\n",
              " 'i',\n",
              " 'remember',\n",
              " 'going',\n",
              " 'to',\n",
              " 'see',\n",
              " 'at',\n",
              " 'the',\n",
              " 'cinema',\n",
              " 'when',\n",
              " 'it',\n",
              " 'was',\n",
              " 'originally',\n",
              " 'released',\n",
              " 'some',\n",
              " 'of',\n",
              " 'it',\n",
              " 'has',\n",
              " 'subtle',\n",
              " 'messages',\n",
              " 'about',\n",
              " 'mjs',\n",
              " 'feeling',\n",
              " 'towards',\n",
              " 'the',\n",
              " 'press',\n",
              " 'and',\n",
              " 'also',\n",
              " 'the',\n",
              " 'obvious',\n",
              " 'message',\n",
              " 'of',\n",
              " 'drugs',\n",
              " 'are',\n",
              " 'bad',\n",
              " 'mkay',\n",
              " 'visually',\n",
              " 'impressive',\n",
              " 'but',\n",
              " 'of',\n",
              " 'course',\n",
              " 'this',\n",
              " 'is',\n",
              " 'all',\n",
              " 'about',\n",
              " 'michael',\n",
              " 'jackson',\n",
              " 'so',\n",
              " 'unless',\n",
              " 'you',\n",
              " 'remotely',\n",
              " 'like',\n",
              " 'mj',\n",
              " 'in',\n",
              " 'anyway',\n",
              " 'then',\n",
              " 'you',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'hate',\n",
              " 'this',\n",
              " 'and',\n",
              " 'find',\n",
              " 'it',\n",
              " 'boring',\n",
              " 'some',\n",
              " 'may',\n",
              " 'call',\n",
              " 'mj',\n",
              " 'an',\n",
              " 'egotist',\n",
              " 'for',\n",
              " 'consenting',\n",
              " 'to',\n",
              " 'the',\n",
              " 'making',\n",
              " 'of',\n",
              " 'this',\n",
              " 'movie',\n",
              " 'but',\n",
              " 'mj',\n",
              " 'and',\n",
              " 'most',\n",
              " 'of',\n",
              " 'his',\n",
              " 'fans',\n",
              " 'would',\n",
              " 'say',\n",
              " 'that',\n",
              " 'he',\n",
              " 'made',\n",
              " 'it',\n",
              " 'for',\n",
              " 'the',\n",
              " 'fans',\n",
              " 'which',\n",
              " 'if',\n",
              " 'true',\n",
              " 'is',\n",
              " 'really',\n",
              " 'nice',\n",
              " 'of',\n",
              " 'him',\n",
              " 'the',\n",
              " 'actual',\n",
              " 'feature',\n",
              " 'film',\n",
              " 'bit',\n",
              " 'when',\n",
              " 'it',\n",
              " 'finally',\n",
              " 'starts',\n",
              " 'is',\n",
              " 'only',\n",
              " 'on',\n",
              " 'for',\n",
              " 'minutes',\n",
              " 'or',\n",
              " 'so',\n",
              " 'excluding',\n",
              " 'the',\n",
              " 'smooth',\n",
              " 'criminal',\n",
              " 'sequence',\n",
              " 'and',\n",
              " 'joe',\n",
              " 'pesci',\n",
              " 'is',\n",
              " 'convincing',\n",
              " 'as',\n",
              " 'a',\n",
              " 'psychopathic',\n",
              " 'all',\n",
              " 'powerful',\n",
              " 'drug',\n",
              " 'lord',\n",
              " 'why',\n",
              " 'he',\n",
              " 'wants',\n",
              " 'mj',\n",
              " 'dead',\n",
              " 'so',\n",
              " 'bad',\n",
              " 'is',\n",
              " 'beyond',\n",
              " 'me',\n",
              " 'because',\n",
              " 'mj',\n",
              " 'overheard',\n",
              " 'his',\n",
              " 'plans',\n",
              " 'nah',\n",
              " 'joe',\n",
              " 'pescis',\n",
              " 'character',\n",
              " 'ranted',\n",
              " 'that',\n",
              " 'he',\n",
              " 'wanted',\n",
              " 'people',\n",
              " 'to',\n",
              " 'know',\n",
              " 'it',\n",
              " 'is',\n",
              " 'he',\n",
              " 'who',\n",
              " 'is',\n",
              " 'supplying',\n",
              " 'drugs',\n",
              " 'etc',\n",
              " 'so',\n",
              " 'i',\n",
              " 'dunno',\n",
              " 'maybe',\n",
              " 'he',\n",
              " 'just',\n",
              " 'hates',\n",
              " 'mjs',\n",
              " 'music',\n",
              " 'lots',\n",
              " 'of',\n",
              " 'cool',\n",
              " 'things',\n",
              " 'in',\n",
              " 'this',\n",
              " 'like',\n",
              " 'mj',\n",
              " 'turning',\n",
              " 'into',\n",
              " 'a',\n",
              " 'car',\n",
              " 'and',\n",
              " 'a',\n",
              " 'robot',\n",
              " 'and',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'speed',\n",
              " 'demon',\n",
              " 'sequence',\n",
              " 'also',\n",
              " 'the',\n",
              " 'director',\n",
              " 'must',\n",
              " 'have',\n",
              " 'had',\n",
              " 'the',\n",
              " 'patience',\n",
              " 'of',\n",
              " 'a',\n",
              " 'saint',\n",
              " 'when',\n",
              " 'it',\n",
              " 'came',\n",
              " 'to',\n",
              " 'filming',\n",
              " 'the',\n",
              " 'kiddy',\n",
              " 'bad',\n",
              " 'sequence',\n",
              " 'as',\n",
              " 'usually',\n",
              " 'directors',\n",
              " 'hate',\n",
              " 'working',\n",
              " 'with',\n",
              " 'one',\n",
              " 'kid',\n",
              " 'let',\n",
              " 'alone',\n",
              " 'a',\n",
              " 'whole',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'them',\n",
              " 'performing',\n",
              " 'a',\n",
              " 'complex',\n",
              " 'dance',\n",
              " 'scene',\n",
              " 'bottom',\n",
              " 'line',\n",
              " 'this',\n",
              " 'movie',\n",
              " 'is',\n",
              " 'for',\n",
              " 'people',\n",
              " 'who',\n",
              " 'like',\n",
              " 'mj',\n",
              " 'on',\n",
              " 'one',\n",
              " 'level',\n",
              " 'or',\n",
              " 'another',\n",
              " 'which',\n",
              " 'i',\n",
              " 'think',\n",
              " 'is',\n",
              " 'most',\n",
              " 'people',\n",
              " 'if',\n",
              " 'not',\n",
              " 'then',\n",
              " 'stay',\n",
              " 'away',\n",
              " 'it',\n",
              " 'does',\n",
              " 'try',\n",
              " 'and',\n",
              " 'give',\n",
              " 'off',\n",
              " 'a',\n",
              " 'wholesome',\n",
              " 'message',\n",
              " 'and',\n",
              " 'ironically',\n",
              " 'mjs',\n",
              " 'bestest',\n",
              " 'buddy',\n",
              " 'in',\n",
              " 'this',\n",
              " 'movie',\n",
              " 'is',\n",
              " 'a',\n",
              " 'girl',\n",
              " 'michael',\n",
              " 'jackson',\n",
              " 'is',\n",
              " 'truly',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'most',\n",
              " 'talented',\n",
              " 'people',\n",
              " 'ever',\n",
              " 'to',\n",
              " 'grace',\n",
              " 'this',\n",
              " 'planet',\n",
              " 'but',\n",
              " 'is',\n",
              " 'he',\n",
              " 'guilty',\n",
              " 'well',\n",
              " 'with',\n",
              " 'all',\n",
              " 'the',\n",
              " 'attention',\n",
              " 'ive',\n",
              " 'gave',\n",
              " 'this',\n",
              " 'subjecthmmm',\n",
              " 'well',\n",
              " 'i',\n",
              " 'dont',\n",
              " 'know',\n",
              " 'because',\n",
              " 'people',\n",
              " 'can',\n",
              " 'be',\n",
              " 'different',\n",
              " 'behind',\n",
              " 'closed',\n",
              " 'doors',\n",
              " 'i',\n",
              " 'know',\n",
              " 'this',\n",
              " 'for',\n",
              " 'a',\n",
              " 'fact',\n",
              " 'he',\n",
              " 'is',\n",
              " 'either',\n",
              " 'an',\n",
              " 'extremely',\n",
              " 'nice',\n",
              " 'but',\n",
              " 'stupid',\n",
              " 'guy',\n",
              " 'or',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'most',\n",
              " 'sickest',\n",
              " 'liars',\n",
              " 'i',\n",
              " 'hope',\n",
              " 'he',\n",
              " 'is',\n",
              " 'not',\n",
              " 'the',\n",
              " 'latter',\n",
              " 'the',\n",
              " 'classic',\n",
              " 'war',\n",
              " 'of',\n",
              " 'the',\n",
              " 'worlds',\n",
              " 'by',\n",
              " 'timothy',\n",
              " 'hines',\n",
              " 'is',\n",
              " 'a',\n",
              " 'very',\n",
              " 'entertaining',\n",
              " 'film',\n",
              " 'that',\n",
              " 'obviously',\n",
              " 'goes',\n",
              " 'to',\n",
              " 'great',\n",
              " 'effort',\n",
              " 'and',\n",
              " 'lengths',\n",
              " 'to',\n",
              " 'faithfully',\n",
              " 'recreate',\n",
              " 'h',\n",
              " 'g',\n",
              " 'wells',\n",
              " 'classic',\n",
              " 'book',\n",
              " 'mr',\n",
              " 'hines',\n",
              " 'succeeds',\n",
              " 'in',\n",
              " 'doing',\n",
              " 'so',\n",
              " 'i',\n",
              " 'and',\n",
              " 'those',\n",
              " 'who',\n",
              " 'watched',\n",
              " 'his',\n",
              " 'film',\n",
              " 'with',\n",
              " 'me',\n",
              " 'appreciated',\n",
              " 'the',\n",
              " 'fact',\n",
              " 'that',\n",
              " 'it',\n",
              " 'was',\n",
              " 'not',\n",
              " 'the',\n",
              " 'standard',\n",
              " 'predictable',\n",
              " 'hollywood',\n",
              " 'fare',\n",
              " 'that',\n",
              " 'comes',\n",
              " 'out',\n",
              " 'every',\n",
              " 'year',\n",
              " 'eg',\n",
              " 'the',\n",
              " 'spielberg',\n",
              " 'version',\n",
              " 'with',\n",
              " 'tom',\n",
              " 'cruise',\n",
              " 'that',\n",
              " 'had',\n",
              " 'only',\n",
              " 'the',\n",
              " 'slightest',\n",
              " 'resemblance',\n",
              " 'to',\n",
              " 'the',\n",
              " 'book',\n",
              " 'obviously',\n",
              " 'everyone',\n",
              " 'looks',\n",
              " 'for',\n",
              " 'different',\n",
              " 'things',\n",
              " 'in',\n",
              " 'a',\n",
              " 'movie',\n",
              " 'those',\n",
              " 'who',\n",
              " 'envision',\n",
              " 'themselves',\n",
              " 'as',\n",
              " 'amateur',\n",
              " 'critics',\n",
              " 'look',\n",
              " 'only',\n",
              " 'to',\n",
              " 'criticize',\n",
              " 'everything',\n",
              " 'they',\n",
              " 'can',\n",
              " 'others',\n",
              " 'rate',\n",
              " 'a',\n",
              " 'movie',\n",
              " 'on',\n",
              " 'more',\n",
              " 'important',\n",
              " 'baseslike',\n",
              " 'being',\n",
              " 'entertained',\n",
              " 'which',\n",
              " 'is',\n",
              " 'why',\n",
              " 'most',\n",
              " 'people',\n",
              " 'never',\n",
              " 'agree',\n",
              " 'with',\n",
              " 'the',\n",
              " 'critics',\n",
              " 'we',\n",
              " 'enjoyed',\n",
              " 'the',\n",
              " 'effort',\n",
              " 'mr',\n",
              " 'hines',\n",
              " 'put',\n",
              " 'into',\n",
              " 'being',\n",
              " 'faithful',\n",
              " 'to',\n",
              " 'hg',\n",
              " 'wells',\n",
              " 'classic',\n",
              " 'novel',\n",
              " 'and',\n",
              " 'we',\n",
              " 'found',\n",
              " 'it',\n",
              " 'to',\n",
              " 'be',\n",
              " 'very',\n",
              " 'entertaining',\n",
              " 'this',\n",
              " 'made',\n",
              " 'it',\n",
              " 'easy',\n",
              " 'to',\n",
              " 'overlook',\n",
              " 'what',\n",
              " 'the',\n",
              " 'critics',\n",
              " 'perceive',\n",
              " 'to',\n",
              " 'be',\n",
              " 'its',\n",
              " 'shortcomings',\n",
              " 'the',\n",
              " 'film',\n",
              " 'starts',\n",
              " 'with',\n",
              " 'a',\n",
              " 'manager',\n",
              " 'nicholas',\n",
              " 'bell',\n",
              " 'giving',\n",
              " 'welcome',\n",
              " 'investors',\n",
              " 'robert',\n",
              " 'carradine',\n",
              " 'to',\n",
              " 'primal',\n",
              " 'park',\n",
              " 'a',\n",
              " 'secret',\n",
              " 'project',\n",
              " 'mutating',\n",
              " 'a',\n",
              " 'primal',\n",
              " 'animal',\n",
              " 'using',\n",
              " 'fossilized',\n",
              " 'dna',\n",
              " 'likejurassik',\n",
              " 'park',\n",
              " 'and',\n",
              " 'some',\n",
              " 'scientists',\n",
              " 'resurrect',\n",
              " 'one',\n",
              " 'of',\n",
              " 'natures',\n",
              " 'most',\n",
              " 'fearsome',\n",
              " 'predators',\n",
              " 'the',\n",
              " 'sabretooth',\n",
              " 'tiger',\n",
              " 'or',\n",
              " 'smilodon',\n",
              " 'scientific',\n",
              " 'ambition',\n",
              " 'turns',\n",
              " 'deadly',\n",
              " 'however',\n",
              " 'and',\n",
              " 'when',\n",
              " 'the',\n",
              " 'high',\n",
              " 'voltage',\n",
              " 'fence',\n",
              " 'is',\n",
              " 'opened',\n",
              " 'the',\n",
              " 'creature',\n",
              " 'escape',\n",
              " 'and',\n",
              " 'begins',\n",
              " 'savagely',\n",
              " 'stalking',\n",
              " 'its',\n",
              " 'prey',\n",
              " 'the',\n",
              " 'human',\n",
              " 'visitors',\n",
              " 'tourists',\n",
              " 'and',\n",
              " 'scientificmeanwhile',\n",
              " 'some',\n",
              " 'youngsters',\n",
              " 'enter',\n",
              " 'in',\n",
              " 'the',\n",
              " 'restricted',\n",
              " 'area',\n",
              " 'of',\n",
              " 'the',\n",
              " 'security',\n",
              " 'center',\n",
              " 'and',\n",
              " 'are',\n",
              " 'attacked',\n",
              " 'by',\n",
              " 'a',\n",
              " 'pack',\n",
              " 'of',\n",
              " 'large',\n",
              " 'prehistorical',\n",
              " 'animals',\n",
              " 'which',\n",
              " 'are',\n",
              " 'deadlier',\n",
              " 'and',\n",
              " 'bigger',\n",
              " 'in',\n",
              " 'addition',\n",
              " 'a',\n",
              " 'security',\n",
              " 'agent',\n",
              " 'stacy',\n",
              " 'haiduk',\n",
              " 'and',\n",
              " 'her',\n",
              " 'mate',\n",
              " 'brian',\n",
              " 'wimmer',\n",
              " 'fight',\n",
              " 'hardly',\n",
              " 'against',\n",
              " 'the',\n",
              " 'carnivorous',\n",
              " 'smilodons',\n",
              " 'the',\n",
              " 'sabretooths',\n",
              " 'themselves',\n",
              " 'of',\n",
              " 'course',\n",
              " 'are',\n",
              " 'the',\n",
              " 'real',\n",
              " 'star',\n",
              " 'stars',\n",
              " 'and',\n",
              " 'they',\n",
              " 'are',\n",
              " 'astounding',\n",
              " 'terrifyingly',\n",
              " 'though',\n",
              " 'not',\n",
              " 'convincing',\n",
              " 'the',\n",
              " 'giant',\n",
              " 'animals',\n",
              " 'savagely',\n",
              " 'are',\n",
              " 'stalking',\n",
              " 'its',\n",
              " 'prey',\n",
              " 'and',\n",
              " 'the',\n",
              " 'group',\n",
              " 'run',\n",
              " 'afoul',\n",
              " 'and',\n",
              " 'fight',\n",
              " 'against',\n",
              " 'one',\n",
              " 'natures',\n",
              " 'most',\n",
              " 'fearsome',\n",
              " 'predators',\n",
              " 'furthermore',\n",
              " 'a',\n",
              " 'third',\n",
              " 'sabretooth',\n",
              " 'more',\n",
              " 'dangerous',\n",
              " 'and',\n",
              " 'slow',\n",
              " 'stalks',\n",
              " 'its',\n",
              " 'victims',\n",
              " 'the',\n",
              " 'movie',\n",
              " 'delivers',\n",
              " 'the',\n",
              " 'goods',\n",
              " 'with',\n",
              " 'lots',\n",
              " 'of',\n",
              " 'blood',\n",
              " 'and',\n",
              " 'gore',\n",
              " 'as',\n",
              " 'beheading',\n",
              " 'hairraising',\n",
              " 'chillsfull',\n",
              " 'of',\n",
              " 'scares',\n",
              " 'when',\n",
              " 'the',\n",
              " 'sabretooths',\n",
              " 'appear',\n",
              " 'with',\n",
              " 'mediocre',\n",
              " 'special',\n",
              " 'effectsthe',\n",
              " 'story',\n",
              " 'provides',\n",
              " 'exciting',\n",
              " 'and',\n",
              " 'stirring',\n",
              " 'entertainment',\n",
              " 'but',\n",
              " 'it',\n",
              " 'results',\n",
              " 'to',\n",
              " 'be',\n",
              " 'quite',\n",
              " 'boring',\n",
              " 'the',\n",
              " 'giant',\n",
              " 'animals',\n",
              " 'are',\n",
              " 'majority',\n",
              " 'made',\n",
              " 'by',\n",
              " 'computer',\n",
              " 'generator',\n",
              " 'and',\n",
              " 'seem',\n",
              " 'totally',\n",
              " 'lousy',\n",
              " 'middling',\n",
              " 'performances',\n",
              " 'though',\n",
              " 'the',\n",
              " 'players',\n",
              " 'reacting',\n",
              " 'appropriately',\n",
              " 'to',\n",
              " 'becoming',\n",
              " 'foodactors',\n",
              " 'give',\n",
              " 'vigorously',\n",
              " 'physical',\n",
              " 'performances',\n",
              " 'dodging',\n",
              " 'the',\n",
              " 'beasts',\n",
              " 'runningbound',\n",
              " 'and',\n",
              " 'leaps',\n",
              " 'or',\n",
              " 'dangling',\n",
              " 'over',\n",
              " 'walls',\n",
              " 'and',\n",
              " 'it',\n",
              " 'packs',\n",
              " 'a',\n",
              " 'ridiculous',\n",
              " 'final',\n",
              " 'deadly',\n",
              " 'scene',\n",
              " 'no',\n",
              " 'for',\n",
              " 'small',\n",
              " 'kids',\n",
              " 'by',\n",
              " 'realisticgory',\n",
              " 'and',\n",
              " 'violent',\n",
              " 'attack',\n",
              " 'scenes',\n",
              " 'other',\n",
              " 'films',\n",
              " 'about',\n",
              " 'sabretooths',\n",
              " 'or',\n",
              " 'smilodon',\n",
              " 'are',\n",
              " 'the',\n",
              " 'following',\n",
              " 'sabretoothby',\n",
              " 'james',\n",
              " 'r',\n",
              " 'hickox',\n",
              " 'with',\n",
              " 'vanessa',\n",
              " 'angel',\n",
              " 'david',\n",
              " 'keith',\n",
              " 'and',\n",
              " 'john',\n",
              " 'rhys',\n",
              " 'davies',\n",
              " 'and',\n",
              " 'the',\n",
              " 'much',\n",
              " 'better',\n",
              " 'bc',\n",
              " 'by',\n",
              " 'roland',\n",
              " 'emmerich',\n",
              " 'with',\n",
              " 'with',\n",
              " 'steven',\n",
              " 'strait',\n",
              " 'cliff',\n",
              " 'curtis',\n",
              " 'and',\n",
              " 'camilla',\n",
              " 'belle',\n",
              " 'this',\n",
              " 'motion',\n",
              " 'picture',\n",
              " 'filled',\n",
              " 'with',\n",
              " 'bloody',\n",
              " 'moments',\n",
              " 'is',\n",
              " 'badly',\n",
              " 'directed',\n",
              " 'by',\n",
              " 'george',\n",
              " 'miller',\n",
              " 'and',\n",
              " 'with',\n",
              " 'no',\n",
              " 'originality',\n",
              " 'because',\n",
              " 'takes',\n",
              " 'too',\n",
              " 'many',\n",
              " 'elements',\n",
              " 'from',\n",
              " 'previous',\n",
              " 'films',\n",
              " 'miller',\n",
              " 'is',\n",
              " 'an',\n",
              " 'australian',\n",
              " 'director',\n",
              " 'usually',\n",
              " 'working',\n",
              " 'for',\n",
              " 'television',\n",
              " 'tidal',\n",
              " 'wave',\n",
              " 'journey',\n",
              " 'to',\n",
              " 'the',\n",
              " 'center',\n",
              " 'of',\n",
              " 'the',\n",
              " 'earth',\n",
              " 'and',\n",
              " 'many',\n",
              " 'others',\n",
              " 'and',\n",
              " 'occasionally',\n",
              " 'for',\n",
              " 'cinema',\n",
              " 'the',\n",
              " 'man',\n",
              " 'from',\n",
              " 'snowy',\n",
              " 'river',\n",
              " 'zeus',\n",
              " 'and',\n",
              " 'roxannerobinson',\n",
              " 'crusoe',\n",
              " 'rating',\n",
              " 'below',\n",
              " 'average',\n",
              " 'bottom',\n",
              " 'of',\n",
              " 'barrel',\n",
              " 'it',\n",
              " 'must',\n",
              " 'be',\n",
              " 'assumed',\n",
              " 'that',\n",
              " 'those',\n",
              " 'who',\n",
              " 'praised',\n",
              " 'this',\n",
              " 'film',\n",
              " 'the',\n",
              " 'greatest',\n",
              " 'filmed',\n",
              " 'opera',\n",
              " 'ever',\n",
              " 'didnt',\n",
              " 'i',\n",
              " 'read',\n",
              " 'somewhere',\n",
              " 'either',\n",
              " 'dont',\n",
              " 'care',\n",
              " 'for',\n",
              " 'opera',\n",
              " 'dont',\n",
              " 'care',\n",
              " 'for',\n",
              " 'wagner',\n",
              " 'or',\n",
              " 'dont',\n",
              " 'care',\n",
              " 'about',\n",
              " 'anything',\n",
              " 'except',\n",
              " 'their',\n",
              " 'desire',\n",
              " 'to',\n",
              " 'appear',\n",
              " 'cultured',\n",
              " 'either',\n",
              " 'as',\n",
              " 'a',\n",
              " 'representation',\n",
              " 'of',\n",
              " 'wagners',\n",
              " 'swansong',\n",
              " 'or',\n",
              " 'as',\n",
              " 'a',\n",
              " 'movie',\n",
              " 'this',\n",
              " 'strikes',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKsJsDqavdGH"
      },
      "source": [
        "**We have tokenised the data so that each word is now in an element of a list. it returns individual words from the given text in the form of a list, this is tokenizer\n",
        "We are using word_tokenize function of nltk here, but alternatively we can also use .split()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF8zkGBC0gJ1",
        "outputId": "122d6eb4-8c9d-4303-c785-195d459658b1"
      },
      "source": [
        "word = list(set(nltk.word_tokenize(text)))\n",
        "print(len(word))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBu_He2nvk9s"
      },
      "source": [
        "**We have taken the set here so that all the duplicates will be removed. And we can see we have 20408 words i.e columns**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXKZ_Y3iwGNG"
      },
      "source": [
        "# **Removing Stopwords**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi1stOpZ0gNt"
      },
      "source": [
        "filtered = list(set([w for w in word if not w in stopwords.words('english')]))\n",
        "print(len(filtered))\n",
        "print(filtered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbeDy8_8vqU6"
      },
      "source": [
        "**Here we have filtered the data so that all the irrelevant words will be removed. And now we can see we have 20275 columns left**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3TznOdHwRd-"
      },
      "source": [
        "# **Lammetization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2BqQuGH0gPn"
      },
      "source": [
        "wordnet_lammetizer = WordNetLemmatizer()"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQNLSrhW0gRt",
        "outputId": "71d052cb-41ae-4c49-f445-bde4672577e6"
      },
      "source": [
        "wordnet_lammetizer_v = []\n",
        "for i in filtered:\n",
        "  wordnet_lammetizer_v.append(wordnet_lammetizer.lemmatize(i,'v'))\n",
        "\n",
        "wordnet_v = list(set(wordnet_lammetizer_v))\n",
        "print(len(wordnet_v))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIRcG9sTwwAc"
      },
      "source": [
        "**After lammetization we are left with 17208 columns or unique words.As we have taken set of the lammetized word, lemmatize to remove repetitive words like play, played to reduce this number.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FOxB4eSxvn0"
      },
      "source": [
        "Till here we have created columns of unique words , using Lammetisation, tokenisation. Now we will create rows but will not take set as we do not want to remove duplicates from the rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFKOhAK0yByu"
      },
      "source": [
        "# **2.Creating Rows to calculate TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcMltM960gTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d70351-fd28-4d99-9c6e-6a34b65920ac"
      },
      "source": [
        "train_file_wordnet_v = []\n",
        "\n",
        "\n",
        "for line in txt['review']:\n",
        "    \n",
        "    x = re.sub('[^a-z ]', '', line.strip().lower())\n",
        "    tokens = nltk.word_tokenize(x)\n",
        "    filtered_tokens = [w for w in tokens if not w in stopwords.words('english')]\n",
        "    stemmed_tokens = ''\n",
        "    for item in filtered_tokens:\n",
        "        stemmed_tokens += wordnet_lammetizer.lemmatize(item, 'v')+' '\n",
        "    train_file_wordnet_v.append(stemmed_tokens[:-1]) # v means verb, we will consider play --> play and played --> play as same \n",
        "# wordnet_v is the new list which has unique non-stopwords and lemmatized words\n",
        "\n",
        "\n",
        "print(len(train_file_wordnet_v))\n",
        "print(train_file_wordnet_v[1])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "classic war worlds timothy hines entertain film obviously go great effort lengths faithfully recreate h g well classic book mr hines succeed watch film appreciate fact standard predictable hollywood fare come every year eg spielberg version tom cruise slightest resemblance book obviously everyone look different things movie envision amateur critics look criticize everything others rate movie important baseslike entertain people never agree critics enjoy effort mr hines put faithful hg well classic novel find entertain make easy overlook critics perceive shortcomings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMY45AL2yMpe"
      },
      "source": [
        "**We have cleaned the rows, like removed the stopwords, applied the tokenisation and lammetization.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PoCn80ngRHk"
      },
      "source": [
        "x = train_file_wordnet_v"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5zqQK15yg9J"
      },
      "source": [
        "**Now let's do the train_test split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY-6PkSOgocv",
        "outputId": "c4c59f62-429a-4732-b799-05647c176abb"
      },
      "source": [
        "len(x)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY2CI9-Xg4Sm"
      },
      "source": [
        "y = txt['sentiment']"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqNeoaX8ftuo"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDtQoBiNgvgx"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=0)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kgkikq29ypaz"
      },
      "source": [
        "**Here we have created the object of the TF_iDF to calculate TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frtk6mJB0gWn"
      },
      "source": [
        "vectorizer = TfidfVectorizer()"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI4uzHzs0gYN"
      },
      "source": [
        "X_train_tfidf = vectorizer.fit_transform(x_train)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khKCwhwDy05_"
      },
      "source": [
        "**We have fit_transform the x_train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OZCvaAI0gcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653aa9f1-ca79-4b5c-c7bf-2b556e22efa1"
      },
      "source": [
        "print(X_train_tfidf.shape)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(700, 13766)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls1fVnQk0gfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b56e672-3cf7-4364-ba3c-dd7a4052cabc"
      },
      "source": [
        "print(type(X_train_tfidf))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDgWydDJ0giO"
      },
      "source": [
        "X_train_tfidf1 = X_train_tfidf.toarray()"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDvBMxrFy-cU"
      },
      "source": [
        "**As model can not take anyother format than pd dataframe or array. so changed it to the array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30Qh-_Wpep2v"
      },
      "source": [
        "X_test_tfidf = vectorizer.transform(x_test)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCzbIVVzMZf"
      },
      "source": [
        "**Transform the X_test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDkNlEhQep1K"
      },
      "source": [
        "X_test_tfidf1 = X_test_tfidf.toarray()"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQMpaHnxzRrw"
      },
      "source": [
        "**Imported the model , we are using Random Forest , as it is a binary classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e3z2AKNepza"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ubx009Jeptr"
      },
      "source": [
        "model_parameters = {\n",
        "        'n_estimators':[ 100],\n",
        "        'criterion':['gini'],\n",
        "        'max_depth': [3, 5]\n",
        "    }"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XtSvKMMepq6",
        "outputId": "c41772c8-b4af-4206-91b3-91a500aef72b"
      },
      "source": [
        "model = RandomForestClassifier(random_state=1)\n",
        "gscv = GridSearchCV(estimator=model, \n",
        "                    param_grid=model_parameters, \n",
        "                    cv=5, \n",
        "                    verbose=1, \n",
        "                    n_jobs=-1,\n",
        "                    scoring='roc_auc')\n",
        "\n",
        "gscv.fit(X_train_tfidf1, y_train)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False, random_state=1,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'criterion': ['gini'], 'max_depth': [3, 5],\n",
              "                         'n_estimators': [100]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='roc_auc', verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xw3k295epne",
        "outputId": "efdd1a84-8809-4e57-98ab-144360591078"
      },
      "source": [
        "print('The best parameter are -', gscv.best_params_)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best parameter are - {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMwHKVG9eplh",
        "outputId": "6d1cde9e-76fa-4e75-ea15-1915b2cd01a5"
      },
      "source": [
        "print(gscv.best_score_)\n",
        "print(gscv.best_estimator_)\n",
        "print(gscv.scorer_)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8394719043870547\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=5, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
            "                       warm_start=False)\n",
            "make_scorer(roc_auc_score, needs_threshold=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViINDw6jh_aD",
        "outputId": "5fe55d51-014e-400d-f7b0-2a1359a5dd87"
      },
      "source": [
        "print('AUC on test by gscv =', roc_auc_score(y_true=y_test,\n",
        "                                                        y_score=gscv.predict_proba(X_test_tfidf1)[:, 1]))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC on test by gscv = 0.8796390950708921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox_mpe2czc9N"
      },
      "source": [
        "We can see the Roc_auc score is 87% using Random Forest with the help of the Grid Search CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0Q5mN3Pwy0m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}